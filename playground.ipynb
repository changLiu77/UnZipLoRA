{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "COLAB = True\n",
    "work_dir = \"/home/changl25/ziplora-pytorch\"\n",
    "os.chdir(work_dir)\n",
    "!pwd\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torch\n",
    "from diffusers import AutoencoderKL, StableDiffusionXLPipeline\n",
    "from transformers import AutoTokenizer\n",
    "MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "weight_dtype = torch.float16\n",
    "rank=64\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from inverse_ziplora_comb_separate import utils\n",
    "from inverse_ziplora_comb_separate.pipeline_stable_diffusion_xl_seperate import StableDiffusionXLSeperatePipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_inverse_ziplora_layer_column import import_model_class_from_model_name_or_path\n",
    "\n",
    "tokenizer_one = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    subfolder=\"tokenizer\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer_two = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    subfolder=\"tokenizer_2\",\n",
    "    use_fast=False,\n",
    ")\n",
    "text_encoder_cls_one = import_model_class_from_model_name_or_path(\n",
    "    MODEL_ID, revision=None\n",
    ")\n",
    "text_encoder_cls_two = import_model_class_from_model_name_or_path(\n",
    "    MODEL_ID, subfolder=\"text_encoder_2\", revision=None\n",
    ")\n",
    "text_encoder_one = text_encoder_cls_one.from_pretrained(\n",
    "    MODEL_ID, subfolder=\"text_encoder\",\n",
    ")\n",
    "text_encoder_two = text_encoder_cls_two.from_pretrained(\n",
    "    MODEL_ID, subfolder=\"text_encoder_2\",\n",
    ")\n",
    "text_encoder_one.requires_grad_(False)\n",
    "text_encoder_one.to(device, dtype=torch.float16)\n",
    "\n",
    "text_encoder_two.requires_grad_(False)\n",
    "text_encoder_two.to(device, dtype=torch.float16)\n",
    "tokenizers = [tokenizer_one, tokenizer_two]\n",
    "text_encoders = [text_encoder_one, text_encoder_two]\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            subfolder=\"vae\",\n",
    "            revision=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_validation(pipeline, prompt, prompt_content, prompt_style, seed=0):\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    # Currently the context determination is a bit hand-wavy. We can improve it in the future if there's a better\n",
    "    # way to condition it. Reference: https://github.com/huggingface/diffusers/pull/7126#issuecomment-1968523051\n",
    "    if pipeline.__class__.__name__ == 'StableDiffusionXLSeperatePipeline':\n",
    "        pipeline_args = {\"prompt\": prompt, \n",
    "                        \"prompt_content\": prompt_content, \n",
    "                        \"prompt_style\": prompt_style}\n",
    "    else: \n",
    "        pipeline_args = {\"prompt\": prompt}\n",
    "    print(pipeline_args)    \n",
    "    images = [pipeline(**pipeline_args, generator=generator, num_inference_steps=50).images[0] for _ in range(4)]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(images):\n",
    "    np_images = np.hstack([np.asarray(img) for img in images])\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np_images)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_single_img(image):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pipeline_unet(output_dir, output_dir2):\n",
    "    content_unet_path = f\"{output_dir}_content\"\n",
    "    style_unet_path = f\"{output_dir2}_style\"\n",
    "    weight_content_path=f\"{output_dir}_merger_content.pth\"\n",
    "    weight_style_path=f\"{output_dir2}_merger_style.pth\"\n",
    "    pipeline = utils.load_pipeline_from_sdxl(\n",
    "        MODEL_ID, vae = vae\n",
    "    )\n",
    "    pipeline.unet = utils.insert_inverse_ziplora_to_unet(pipeline.unet,\n",
    "        content_unet_path, \n",
    "        style_unet_path, \n",
    "        weight_content_path,\n",
    "        weight_style_path,      \n",
    "        rank=64)\n",
    "    pipeline = pipeline.to(device, dtype=weight_dtype)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pipeline(pipeline):\n",
    "    del pipeline\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content / Style Individual Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"rose\"\n",
    "style = \"pop art\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"\"\n",
    "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    vae=vae,\n",
    "    torch_dtype=weight_dtype,\n",
    ")\n",
    "pipeline.load_lora_weights(f\"{model_dir}_content\")\n",
    "prompt_content_main = f\"A photo of monadikos {content}\"\n",
    "prompt_content = f\"A photo of monadikos {content}\"\n",
    "imgs_content = log_validation(pipeline, prompt_content, prompt_content, prompt_content)\n",
    "show_img(imgs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.load_lora_weights(f\"{model_dir}_style\")\n",
    "prompt_style = f\"a dog in {style} style\"\n",
    "pipeline.unet = utils.inverse_ziplora_set_forward_type(pipeline.unet, type=\"style\")\n",
    "\n",
    "imgs_style = log_validation(pipeline, prompt_style, prompt_style, prompt_style)\n",
    "show_img(imgs_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use UnZipLoRA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_content = \"\"\n",
    "model_dir_style = \"\"\n",
    "pipeline = load_pipeline_unet(model_dir_content, model_dir_style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_content_main = f\"A photo of monadikos {content}\"\n",
    "prompt_content = f\"A photo of monadikos {content}\"\n",
    "pipeline.unet = utils.inverse_ziplora_set_forward_type(pipeline.unet, type=\"content\")\n",
    "\n",
    "# imgs_content = log_validation(pipeline, prompt_content_main, prompt_content, prompt_content)\n",
    "imgs_content = log_validation(pipeline, prompt_content, prompt_content, prompt_content)\n",
    "show_img(imgs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = f\"a dog in {style} style\"\n",
    "pipeline.unet = utils.inverse_ziplora_set_forward_type(pipeline.unet, type=\"style\")\n",
    "\n",
    "imgs_style = log_validation(pipeline, prompt_style, prompt_style, prompt_style)\n",
    "show_img(imgs_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_combine = f\"a monadikos {content} in {style} style on a skateboard\"\n",
    "prompt_combine_content = f\"a monadikos {content} on a skateboard\"\n",
    "prompt_combine_style = f\"a {content} in {style} style on a skateboard\"\n",
    "\n",
    "pipeline.unet = utils.inverse_ziplora_set_forward_type(pipeline.unet, type=\"both\")\n",
    "imgs = log_validation(pipeline, prompt_combine, prompt_combine_content, prompt_combine_style)\n",
    "show_img(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_content = \"\"\n",
    "model_dir_style = \"\"\n",
    "content_prompt = \"rose\"\n",
    "style_prompt = \"geometry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = load_pipeline_unet(model_dir_content, model_dir_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_combine = f\"a monadikos {content_prompt} in {style_prompt} style\"\n",
    "prompt_combine_content = f\"a monadikos {content_prompt} \"\n",
    "prompt_combine_style = f\"a {content_prompt} in {style_prompt} style\"\n",
    "\n",
    "pipeline.unet = utils.inverse_ziplora_set_forward_type(pipeline.unet, type=\"both\")\n",
    "imgs = log_validation(pipeline, prompt_combine, prompt_combine_content, prompt_combine_style)\n",
    "show_img(imgs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
